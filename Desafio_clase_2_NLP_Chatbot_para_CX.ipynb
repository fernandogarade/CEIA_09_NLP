{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Desafio clase 2 NLP - Chatbot para CX.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPHH6iSvSdxyoHfY5LrJDyt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f0b94b5f68e44cf19fcd403511749892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f9a10c730b654028b56ba25e6a7ce035",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_26dcfcf080e744e592ba020a5b66dc9b",
              "IPY_MODEL_761f3be90e75452489972c61b4a7a154",
              "IPY_MODEL_621b163f5d934dc6997a738a437489b6"
            ]
          }
        },
        "f9a10c730b654028b56ba25e6a7ce035": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "26dcfcf080e744e592ba020a5b66dc9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3aa7dce066584c3b85aec1543cab8c97",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.2.2.json: ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_400c0fe93643429399eb05c8f463d9f7"
          }
        },
        "761f3be90e75452489972c61b4a7a154": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_218bf6441ae24a6981c48c4460f5ad42",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 24144,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 24144,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad339a568e3849cbb495b5af6c8a72d8"
          }
        },
        "621b163f5d934dc6997a738a437489b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3c9254c2490d47f0b36cf5258919d69b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 140k/? [00:00&lt;00:00, 2.36MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3dbcc4638e494660a0dab3810a2792a1"
          }
        },
        "3aa7dce066584c3b85aec1543cab8c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "400c0fe93643429399eb05c8f463d9f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "218bf6441ae24a6981c48c4460f5ad42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad339a568e3849cbb495b5af6c8a72d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c9254c2490d47f0b36cf5258919d69b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3dbcc4638e494660a0dab3810a2792a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fernandogarade/CEIA_09_NLP/blob/main/Desafio_clase_2_NLP_Chatbot_para_CX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L80OIgRNwRGV"
      },
      "source": [
        "## 1 - Instalar dependencias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhS8XMtyvnwZ"
      },
      "source": [
        "# La última versión de spacy-stanza (>1.0) es compatible solo con spacy >=3.0\n",
        "# Nota: spacy 3.0 incorpora al pepiline nlp transformers\n",
        "!pip install -U spacy==3.1 --quiet\n",
        "!pip install -U spacy-stanza==1.0.0 --quiet"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYUHFxilwa8v"
      },
      "source": [
        "# 2 - Importar librerías"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tVBr6r4waL4"
      },
      "source": [
        "import json\n",
        "import string\n",
        "import random \n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf \n",
        "from tensorflow.keras import Sequential \n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "import stanza\n",
        "import spacy_stanza\n",
        "\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491,
          "referenced_widgets": [
            "f0b94b5f68e44cf19fcd403511749892",
            "f9a10c730b654028b56ba25e6a7ce035",
            "26dcfcf080e744e592ba020a5b66dc9b",
            "761f3be90e75452489972c61b4a7a154",
            "621b163f5d934dc6997a738a437489b6",
            "3aa7dce066584c3b85aec1543cab8c97",
            "400c0fe93643429399eb05c8f463d9f7",
            "218bf6441ae24a6981c48c4460f5ad42",
            "ad339a568e3849cbb495b5af6c8a72d8",
            "3c9254c2490d47f0b36cf5258919d69b",
            "3dbcc4638e494660a0dab3810a2792a1"
          ]
        },
        "id": "VC-bkPgD5NIn",
        "outputId": "7d79651f-db8d-4773-e21d-08ec21f9d804"
      },
      "source": [
        "# Descargar el diccionario en español y armar el pipeline de NLP con spacy\n",
        "stanza.download(\"es\")\n",
        "nlp = spacy_stanza.load_pipeline(\"es\")\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0b94b5f68e44cf19fcd403511749892",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.2.2.json:   0%|   …"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-09-21 02:13:56 INFO: Downloading default packages for language: es (Spanish)...\n",
            "2021-09-21 02:13:58 INFO: File exists: /root/stanza_resources/es/default.zip.\n",
            "2021-09-21 02:14:05 INFO: Finished downloading models and saved to /root/stanza_resources.\n",
            "2021-09-21 02:14:05 INFO: Loading these models for language: es (Spanish):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | ancora  |\n",
            "| mwt       | ancora  |\n",
            "| pos       | ancora  |\n",
            "| lemma     | ancora  |\n",
            "| depparse  | ancora  |\n",
            "| ner       | conll02 |\n",
            "=======================\n",
            "\n",
            "2021-09-21 02:14:05 INFO: Use device: cpu\n",
            "2021-09-21 02:14:05 INFO: Loading: tokenize\n",
            "2021-09-21 02:14:05 INFO: Loading: mwt\n",
            "2021-09-21 02:14:05 INFO: Loading: pos\n",
            "2021-09-21 02:14:06 INFO: Loading: lemma\n",
            "2021-09-21 02:14:06 INFO: Loading: depparse\n",
            "2021-09-21 02:14:06 INFO: Loading: ner\n",
            "2021-09-21 02:14:08 INFO: Done loading processors!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeDI5GvZ5YXQ"
      },
      "source": [
        "# Funciones útiles\n",
        "def cosine_similarity(a, b):\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))\n",
        "\n",
        "def OHE(x,vocab):\n",
        "  vector_ohe = [1 if i in x else 0 for i in vocab ]\n",
        "  vector_ohe = np.array(vector_ohe)\n",
        "  return vector_ohe\n",
        "\n",
        "def FreqVector(x,vocab):\n",
        "  c = Counter(x)\n",
        "  vector_frec = [c[i] for i in vocab ]\n",
        "  vector_frec = np.array(vector_frec)\n",
        "  return vector_frec"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaTLJegRwmeL"
      },
      "source": [
        "# 3 - Preprocesamiento de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aP5oQ72wk4t"
      },
      "source": [
        "# El preprocesamento en castellano requiere más trabajo\n",
        "\n",
        "def preprocess_clean_text(text):    \n",
        "    # sacar tildes de las palabras\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    \n",
        "    # quitar caracteres especiales y números\n",
        "    pattern = r'[^a-zA-z.,!?/:;\\\"\\'\\s]' \n",
        "    text = re.sub(pattern, '', text)\n",
        "\n",
        "    # quitar caracteres de puntuación\n",
        "    text = ''.join([c for c in text if c not in string.punctuation])\n",
        "\n",
        "    return text"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dn2_yKIM0amC"
      },
      "source": [
        "# 4 - Diccionario de entrada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCDyYHNx0Zn7"
      },
      "source": [
        "# Dataset en formato JSON que representa las posibles preguntas (patterns)\n",
        "# y las posibles respuestas por categoría (tag)\n",
        "dataset = {\"intents\": [\n",
        "             {\"tag\": \"bienvenida\",\n",
        "              \"patterns\": [\"Hola\", \"¿Cómo estás?\", \"¿Qué tal?\", \"¿Qué haces?\", \"Buen día\", \"Buenas tardes\", \"Buenas noches\"],\n",
        "              \"responses\": [\"Hola!\", \"Hola, ¿Cómo estás?\"],\n",
        "             },\n",
        "             {\"tag\": \"nombre\",\n",
        "              \"patterns\": [\"¿Cúal es tu nombre?\", \"¿Quién sos?\", \"¿Con quién estoy hablando?\"],\n",
        "              \"responses\": [\"Mi nombre es TiendaPro\", \"Yo soy TiendaPro\"]\n",
        "             },\n",
        "            {\"tag\": \"problemas promos\",\n",
        "              \"patterns\": [\"No me pagaron la promo\", \"Recomendé y no me pagaron\", \"Problema\", \"inconveniente\"],\n",
        "              \"responses\": [\"Lamentamos saber que tuviste un problema con la promo, por favor al siguiente número 1112221133\", \"Contactanos al whatsapp 1112221133 para revisar tu caso en forma particular\"]\n",
        "             },\n",
        "            {\"tag\": \"info promos\",\n",
        "              \"patterns\": [\"¿Cómo funciona la promo?\", \"¿Cómo tengo que hacer para referir a alguien?\", \"¿Cuándo me pagan?\", \"¿Hasta cuándo está vigente?\", \"¿Cuándo termina la promo?\"],\n",
        "              \"responses\": [\"Encontrá todos los detalles de nuestras promos en el siguiente link: abc123.com\"]\n",
        "             },\n",
        "            {\"tag\": \"costo\",\n",
        "              \"patterns\": [\"costo\", \"precio\", \"¿Cuánto vale?\", \"¿Cuánto sale?\", \"¿Tengo que pagar algo?\", \"gratis\"],\n",
        "              \"responses\": [\"El servicio es GRATIS!\"]\n",
        "             },\n",
        "            {\"tag\": \"registro\",\n",
        "              \"patterns\": [\"registro\", \"darse de alta\", \"¿Cómo me doy de alta?\", \"¿Dónde me inscribo?\"],\n",
        "              \"responses\": [\"En el siguiente link podrás encontrar un instructivo para registrarte fácilmente\"]\n",
        "             },\n",
        "            {\"tag\": \"agradecimientos\",\n",
        "              \"patterns\": [ \"Muchas gracias\", \"Gracias\"],\n",
        "              \"responses\": [\"Por nada!, cualquier otra consulta podes escribirme nuevamente\"]\n",
        "             },\n",
        "             {\"tag\": \"despedida\",\n",
        "              \"patterns\": [ \"Chau\", \"Hasta luego!\", \"Nos vemos\"],\n",
        "              \"responses\": [\"Hasta luego!\", \"Hablamos luego!\"]\n",
        "             }\n",
        "]}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw-Fj1Xi3MlU"
      },
      "source": [
        "# 5 - Preprocesamiento y armado del dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lza-APNX3PcI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a60ccfb6-69c3-470f-a1ac-a608536fbc0b"
      },
      "source": [
        "# Datos que necesitaremos, las palabras o vocabulario\n",
        "words = []\n",
        "classes = []\n",
        "doc_X = []\n",
        "doc_y = []\n",
        "\n",
        "# Por cada intención (intents) debemos tomar los patrones que la caracterízan a esa intención y transformarla a tokens para almacenar en doc_X\n",
        "\n",
        "# El tag de cada intención se almacena como doc_Y (la clase a predecir)\n",
        "nltk_stop_words = set(stopwords.words(\"spanish\"))\n",
        "\n",
        "for intent in dataset[\"intents\"]:\n",
        "    for pattern in intent[\"patterns\"]:\n",
        "        # trasformar el patron a tokens\n",
        "        tokens = nlp(preprocess_clean_text(pattern.lower()))\n",
        "        # lematizar los tokens\n",
        "        for token in tokens:            \n",
        "            if token.lemma_ not in nltk_stop_words:\n",
        "              words.append(token.lemma_)\n",
        "        \n",
        "        doc_X.append(pattern)\n",
        "        doc_y.append(intent[\"tag\"])\n",
        "    \n",
        "    # Agregar el tag a las clases\n",
        "    if intent[\"tag\"] not in classes:\n",
        "        classes.append(intent[\"tag\"])\n",
        "\n",
        "# Elminar duplicados con \"set\" y ordenar el vocubulario y las clases por orden alfabético\n",
        "words = sorted(set(words))\n",
        "classes = sorted(set(classes))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
            "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
            "  return torch.floor_divide(self, other)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjZ7kGqD3pNC",
        "outputId": "27a1a111-3fd8-4e60-f8c6-a6e79939b867"
      },
      "source": [
        "print(\"words:\", words)\n",
        "print(\"classes:\", classes)\n",
        "print(\"doc_X:\", doc_X)\n",
        "print(\"doc_y:\", doc_y)\n",
        "# Tamaño del vocabulario\n",
        "print(\"Vocabulario:\", len(words))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "words: ['alguien', 'alta', 'buen', 'chau', 'costo', 'cuanto', 'dar', 'dia', 'funcionar', 'gracias', 'gratis', 'hablar', 'hacer', 'holar', 'inconveniente', 'inscribir', 'luego', 'noche', 'nombre', 'pagar', 'precio', 'problema', 'promo', 'recomendar', 'referir', 'registro', 'salir', 'ser', 'tal', 'tarde', 'tener', 'terminar', 'valer', 'ver', 'vigente']\n",
            "classes: ['agradecimientos', 'bienvenida', 'costo', 'despedida', 'info promos', 'nombre', 'problemas promos', 'registro']\n",
            "doc_X: ['Hola', '¿Cómo estás?', '¿Qué tal?', '¿Qué haces?', 'Buen día', 'Buenas tardes', 'Buenas noches', '¿Cúal es tu nombre?', '¿Quién sos?', '¿Con quién estoy hablando?', 'No me pagaron la promo', 'Recomendé y no me pagaron', 'Problema', 'inconveniente', '¿Cómo funciona la promo?', '¿Cómo tengo que hacer para referir a alguien?', '¿Cuándo me pagan?', '¿Hasta cuándo está vigente?', '¿Cuándo termina la promo?', 'costo', 'precio', '¿Cuánto vale?', '¿Cuánto sale?', '¿Tengo que pagar algo?', 'gratis', 'registro', 'darse de alta', '¿Cómo me doy de alta?', '¿Dónde me inscribo?', 'Muchas gracias', 'Gracias', 'Chau', 'Hasta luego!', 'Nos vemos']\n",
            "doc_y: ['bienvenida', 'bienvenida', 'bienvenida', 'bienvenida', 'bienvenida', 'bienvenida', 'bienvenida', 'nombre', 'nombre', 'nombre', 'problemas promos', 'problemas promos', 'problemas promos', 'problemas promos', 'info promos', 'info promos', 'info promos', 'info promos', 'info promos', 'costo', 'costo', 'costo', 'costo', 'costo', 'costo', 'registro', 'registro', 'registro', 'registro', 'agradecimientos', 'agradecimientos', 'despedida', 'despedida', 'despedida']\n",
            "Vocabulario: 35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJYhODU35zmi"
      },
      "source": [
        "# Opción con TF-IDF\n",
        "# Transformar doc_X en TF_IDF\n",
        "# Transformar doc_Y en un vector de clases multicategórico con oneHotEncoding\n",
        "\n",
        "vocab = words\n",
        "corpus = doc_X\n",
        "\n",
        "corpus_terminos = []\n",
        "for doc in corpus:\n",
        "  tokens = nlp(preprocess_clean_text(doc.lower()))\n",
        "  terminos = []\n",
        "  for token in tokens:\n",
        "      if token.lemma_ not in nltk_stop_words:\n",
        "        terminos.append(token.lemma_)\n",
        "  \n",
        "  corpus_terminos.append(terminos)\n",
        "\n",
        "N = len(corpus)\n",
        "ohe = np.zeros((len(corpus),len(vocab)))\n",
        "TF = np.zeros((len(corpus),len(vocab)))\n",
        "i = 0\n",
        "for doc in corpus_terminos:\n",
        "  ohe[i] = OHE(doc,vocab)\n",
        "  TF[i] = FreqVector(doc,vocab)\n",
        "  i += 1\n",
        "\n",
        "DF = np.sum(ohe,axis=0)\n",
        "IDF = np.log10(N/DF)\n",
        "TF_IDF = TF*IDF"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zwmcd0B6-717"
      },
      "source": [
        "ohe_y = np.zeros(shape=(len(doc_y),len(classes)))\n",
        "i = 0\n",
        "for doc in doc_y:\n",
        "  ohe_y[i] = OHE(doc,classes)\n",
        "  i += 1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef8PGADN9q4z"
      },
      "source": [
        "x_train = TF_IDF\n",
        "y_train = ohe_y"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYIaNtAiCWMn",
        "outputId": "421acaab-7c8e-4738-d135-c683f3ab4a94"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(34, 35)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoSmQ_hwCYzz",
        "outputId": "33bbe504-7fa3-4c99-97a1-4479b80e3d46"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(34, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFxmdA_N4RKH"
      },
      "source": [
        "# 6 - Entrenamiento del modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3xBGRtM4NKU",
        "outputId": "f0132d37-c06e-4cad-afc5-4a9ada281396"
      },
      "source": [
        "# Shape de entrada y salida\n",
        "input_shape = (x_train.shape[1],)\n",
        "output_shape = y_train.shape[1]\n",
        "\n",
        "# Entrenamiento del modelo DNN\n",
        "# - Modelo secuencial\n",
        "# - Con regularización\n",
        "# - softmax y optimizador Adam\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=input_shape, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(output_shape, activation = \"softmax\"))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=\"Adam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "print(model.summary())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               4608      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 520       \n",
            "=================================================================\n",
            "Total params: 13,384\n",
            "Trainable params: 13,384\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGTwiOv84Vzq",
        "outputId": "7577ebfc-f479-4972-c459-5e9f1d38bf02"
      },
      "source": [
        "hist = model.fit(x=x_train, y=y_train, epochs=200)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "2/2 [==============================] - 1s 9ms/step - loss: 2.1013 - accuracy: 0.1765\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 2.0794 - accuracy: 0.1765\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 2.1649 - accuracy: 0.0294\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 2.0227 - accuracy: 0.2941\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0787 - accuracy: 0.1471\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 2.0069 - accuracy: 0.2647\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0045 - accuracy: 0.2647\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 2.0443 - accuracy: 0.0882\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.9683 - accuracy: 0.1765\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.0085 - accuracy: 0.1471\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.9300 - accuracy: 0.3529\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 2.0267 - accuracy: 0.1765\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.9799 - accuracy: 0.1765\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.9527 - accuracy: 0.2647\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1.9734 - accuracy: 0.2353\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.9379 - accuracy: 0.3235\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.9555 - accuracy: 0.3529\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.9438 - accuracy: 0.4412\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.8854 - accuracy: 0.3529\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.8955 - accuracy: 0.3529\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 1.8834 - accuracy: 0.3529\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.9151 - accuracy: 0.3824\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.8107 - accuracy: 0.5000\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.8882 - accuracy: 0.2941\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8462 - accuracy: 0.4118\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.8983 - accuracy: 0.3529\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.7911 - accuracy: 0.5294\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.8385 - accuracy: 0.3529\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.8162 - accuracy: 0.3824\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 1.8542 - accuracy: 0.4118\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1.8130 - accuracy: 0.4412\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 1.7826 - accuracy: 0.4118\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.7898 - accuracy: 0.5588\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1.8289 - accuracy: 0.4118\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 1.8034 - accuracy: 0.3529\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 1.7699 - accuracy: 0.4706\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 1.7820 - accuracy: 0.4118\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 1.7189 - accuracy: 0.4412\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.7281 - accuracy: 0.5294\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 1.7680 - accuracy: 0.4412\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.6407 - accuracy: 0.5588\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.7143 - accuracy: 0.4412\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.7520 - accuracy: 0.2941\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.6948 - accuracy: 0.4706\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.6820 - accuracy: 0.6176\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.7278 - accuracy: 0.3824\n",
            "Epoch 47/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.7358 - accuracy: 0.4412\n",
            "Epoch 48/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.6380 - accuracy: 0.6471\n",
            "Epoch 49/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.5728 - accuracy: 0.5588\n",
            "Epoch 50/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.6051 - accuracy: 0.6471\n",
            "Epoch 51/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.5817 - accuracy: 0.6176\n",
            "Epoch 52/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.6257 - accuracy: 0.5588\n",
            "Epoch 53/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.5695 - accuracy: 0.6765\n",
            "Epoch 54/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.5473 - accuracy: 0.6176\n",
            "Epoch 55/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.5026 - accuracy: 0.6176\n",
            "Epoch 56/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.4397 - accuracy: 0.6765\n",
            "Epoch 57/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.5839 - accuracy: 0.5000\n",
            "Epoch 58/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.4542 - accuracy: 0.6176\n",
            "Epoch 59/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.5343 - accuracy: 0.5000\n",
            "Epoch 60/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.6029 - accuracy: 0.5294\n",
            "Epoch 61/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.4558 - accuracy: 0.6471\n",
            "Epoch 62/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.4461 - accuracy: 0.6176\n",
            "Epoch 63/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.4235 - accuracy: 0.6765\n",
            "Epoch 64/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.5195 - accuracy: 0.5882\n",
            "Epoch 65/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.4091 - accuracy: 0.7353\n",
            "Epoch 66/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.3969 - accuracy: 0.6176\n",
            "Epoch 67/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.3000 - accuracy: 0.7941\n",
            "Epoch 68/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.4797 - accuracy: 0.5294\n",
            "Epoch 69/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.4495 - accuracy: 0.6176\n",
            "Epoch 70/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.3184 - accuracy: 0.7353\n",
            "Epoch 71/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2824 - accuracy: 0.7059\n",
            "Epoch 72/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.3149 - accuracy: 0.7059\n",
            "Epoch 73/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.3593 - accuracy: 0.7353\n",
            "Epoch 74/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.3890 - accuracy: 0.6176\n",
            "Epoch 75/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.3614 - accuracy: 0.5882\n",
            "Epoch 76/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.4139 - accuracy: 0.5882\n",
            "Epoch 77/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.1688 - accuracy: 0.7647\n",
            "Epoch 78/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.2304 - accuracy: 0.7353\n",
            "Epoch 79/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.3037 - accuracy: 0.6765\n",
            "Epoch 80/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.2850 - accuracy: 0.7059\n",
            "Epoch 81/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.2730 - accuracy: 0.6471\n",
            "Epoch 82/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.1926 - accuracy: 0.6471\n",
            "Epoch 83/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2926 - accuracy: 0.6176\n",
            "Epoch 84/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.1028 - accuracy: 0.7059\n",
            "Epoch 85/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.2239 - accuracy: 0.7059\n",
            "Epoch 86/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.1833 - accuracy: 0.5882\n",
            "Epoch 87/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2610 - accuracy: 0.7059\n",
            "Epoch 88/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.2003 - accuracy: 0.6176\n",
            "Epoch 89/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1972 - accuracy: 0.7647\n",
            "Epoch 90/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1224 - accuracy: 0.7941\n",
            "Epoch 91/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.1229 - accuracy: 0.8529\n",
            "Epoch 92/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.0352 - accuracy: 0.7353\n",
            "Epoch 93/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.1711 - accuracy: 0.6765\n",
            "Epoch 94/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.1290 - accuracy: 0.7059\n",
            "Epoch 95/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.1125 - accuracy: 0.7647\n",
            "Epoch 96/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.1716 - accuracy: 0.7059\n",
            "Epoch 97/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1842 - accuracy: 0.6471\n",
            "Epoch 98/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.0654 - accuracy: 0.6471\n",
            "Epoch 99/200\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.0842 - accuracy: 0.7647\n",
            "Epoch 100/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.1356 - accuracy: 0.7059\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.9808 - accuracy: 0.7647\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.2131 - accuracy: 0.6176\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.9831 - accuracy: 0.7941\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.1269 - accuracy: 0.6765\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.0162 - accuracy: 0.7353\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9134 - accuracy: 0.7941\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9591 - accuracy: 0.7941\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.9457 - accuracy: 0.8824\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.9345 - accuracy: 0.6765\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.0193 - accuracy: 0.7647\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.9574 - accuracy: 0.7941\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8943 - accuracy: 0.7941\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8435 - accuracy: 0.8235\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9293 - accuracy: 0.8529\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.0374 - accuracy: 0.6176\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.0154 - accuracy: 0.6471\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8526 - accuracy: 0.7647\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8656 - accuracy: 0.7941\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8730 - accuracy: 0.8235\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8375 - accuracy: 0.8824\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8602 - accuracy: 0.7353\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8831 - accuracy: 0.8235\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.8220 - accuracy: 0.8529\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8687 - accuracy: 0.7941\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8188 - accuracy: 0.7647\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7416 - accuracy: 0.7941\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6974 - accuracy: 0.9118\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8677 - accuracy: 0.9118\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7960 - accuracy: 0.9412\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7238 - accuracy: 0.7941\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7507 - accuracy: 0.7941\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7677 - accuracy: 0.8529\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8527 - accuracy: 0.7941\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7879 - accuracy: 0.7941\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6762 - accuracy: 0.8824\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6672 - accuracy: 0.9118\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7188 - accuracy: 0.8529\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7180 - accuracy: 0.8529\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8009 - accuracy: 0.8529\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6321 - accuracy: 0.9118\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6915 - accuracy: 0.8529\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7351 - accuracy: 0.8529\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5583 - accuracy: 0.8824\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.7680 - accuracy: 0.8235\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.7306 - accuracy: 0.8824\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.5731 - accuracy: 0.9412\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5652 - accuracy: 0.9118\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7217 - accuracy: 0.9118\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6738 - accuracy: 0.9118\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5388 - accuracy: 0.9118\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5763 - accuracy: 0.8529\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6337 - accuracy: 0.9118\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5383 - accuracy: 0.9412\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5010 - accuracy: 0.9706\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.5740 - accuracy: 0.8529\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.4483 - accuracy: 0.9412\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6000 - accuracy: 0.9118\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.5301 - accuracy: 0.9706\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4981 - accuracy: 0.9412\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5594 - accuracy: 0.8529\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5658 - accuracy: 0.8824\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6043 - accuracy: 0.9118\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6000 - accuracy: 0.9118\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5915 - accuracy: 0.8529\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4603 - accuracy: 0.9118\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.9412\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.9118\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5860 - accuracy: 0.8824\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5155 - accuracy: 0.9118\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5005 - accuracy: 0.9118\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4547 - accuracy: 0.9412\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4708 - accuracy: 0.9706\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4506 - accuracy: 0.9706\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4794 - accuracy: 0.9118\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3818 - accuracy: 0.9706\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.9412\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4803 - accuracy: 0.8824\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4267 - accuracy: 0.9706\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5519 - accuracy: 0.8529\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5320 - accuracy: 0.8824\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4942 - accuracy: 0.9118\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.4182 - accuracy: 0.9412\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5180 - accuracy: 0.9118\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4499 - accuracy: 0.8824\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3489 - accuracy: 0.9412\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5077 - accuracy: 0.9412\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5004 - accuracy: 0.9118\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4623 - accuracy: 0.8824\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3810 - accuracy: 0.9706\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4787 - accuracy: 0.8824\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.8824\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.9412\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3400 - accuracy: 0.9706\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3770 - accuracy: 0.8529\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.8824\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3690 - accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.9706\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.2986 - accuracy: 0.9706\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.3088 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "mzWmDpAV4Xm_",
        "outputId": "3484bade-5521-423b-f4ac-5663b8857e5a"
      },
      "source": [
        "# Entrenamiento\n",
        "epoch_count = range(1, len(hist.history['accuracy']) + 1)\n",
        "sns.lineplot(x=epoch_count,  y=hist.history['accuracy'], label='train')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_djA5zBU4gip"
      },
      "source": [
        "# Guardar lo necesario para poder re-utilizar este modelo en el futuro\n",
        "# el vocabulario utilizado (words)\n",
        "# las posibles clases\n",
        "# el modelo\n",
        "\n",
        "import pickle\n",
        "pickle.dump(words, open('words.pkl','wb'))\n",
        "pickle.dump(classes, open('classes.pkl','wb'))\n",
        "model.save('chatbot_model.h5')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDovZ3544jv_"
      },
      "source": [
        "# 7 - Testing y validación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bxevS3PCvgt"
      },
      "source": [
        "def doc_to_terminos(doc):\n",
        "  tokens = nlp(preprocess_clean_text(doc.lower()))\n",
        "  terminos = []\n",
        "  for token in tokens:\n",
        "      if token.lemma_ not in nltk_stop_words:\n",
        "        terminos.append(token.lemma_)\n",
        "  return terminos\n",
        "\n",
        "\n",
        "def calc_TF_IDF(doc,vocab,IDF):\n",
        "  terminos = doc_to_terminos(doc)\n",
        "  TF = FreqVector(terminos,vocab)\n",
        "  TF_IDF = TF*IDF\n",
        "  \n",
        "  return TF_IDF\n",
        "\n",
        "def pred_class(doc,vocab,labels,IDF):\n",
        "  TF_IDF = calc_TF_IDF(doc,vocab,IDF)\n",
        "  words_recognized = sum(TF_IDF)\n",
        "\n",
        "  return_list = []\n",
        "  if words_recognized > 0:\n",
        "    result = model.predict(np.array([TF_IDF]))[0]\n",
        "    thresh = 0.2\n",
        "    y_pred = [[idx, res] for idx, res in enumerate(result) if res > thresh]\n",
        "    y_pred.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    for r in y_pred:\n",
        "      return_list.append(labels[r[0]])\n",
        "      #print(labels[r[0]], r[1])\n",
        "\n",
        "  return return_list\n",
        "\n",
        "def get_response(intents_list, intents_json):\n",
        "  tag = intents_list[0]\n",
        "  list_of_intents = intents_json[\"intents\"]\n",
        "  for i in list_of_intents: \n",
        "      if i[\"tag\"] == tag:\n",
        "          result = \"BOT: \" + random.choice(i[\"responses\"])\n",
        "          break\n",
        "  return result"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nSTL-XdS4onz",
        "outputId": "a35a6b13-f0bf-4ec8-a393-3281f25048b1"
      },
      "source": [
        "while True:\n",
        "    message = input(\"\")\n",
        "    intents = pred_class(doc=message, vocab=vocab, labels=classes,IDF=IDF)\n",
        "    if len(intents) > 0:\n",
        "        result = get_response(intents, dataset)\n",
        "        print(result)\n",
        "    else:\n",
        "        print(\"Perdón, no comprendo la pregunta.\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Buen día\n",
            "BOT: Hola!\n",
            "Quién está ahí?\n",
            "Perdón, no comprendo la pregunta.\n",
            "Quién\n",
            "Perdón, no comprendo la pregunta.\n",
            "Cómo es tu nombre\n",
            "BOT: Mi nombre es TiendaPro\n",
            "Quién sos\n",
            "BOT: Mi nombre es TiendaPro\n",
            "No me pagaron\n",
            "BOT: Encontrá todos los detalles de nuestras promos en el siguiente link: abc123.com\n",
            "ok hasta cuando funciona\n",
            "BOT: Encontrá todos los detalles de nuestras promos en el siguiente link: abc123.com\n",
            "tuve un inconveniente\n",
            "BOT: Contactanos al whatsapp 1112221133 para revisar tu caso en forma particular\n",
            "ok pero tengo que pagar algo?\n",
            "BOT: El servicio es GRATIS!\n",
            "Buenísimo y cómo me anoto?\n",
            "Perdón, no comprendo la pregunta.\n",
            "que como me registro\n",
            "BOT: En el siguiente link podrás encontrar un instructivo para registrarte fácilmente\n",
            "Buenísimo muchas gracias\n",
            "BOT: Por nada!, cualquier otra consulta podes escribirme nuevamente\n",
            "Dale genial hasta luego\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: Due to multiword token expansion or an alignment issue, the original text has been replaced by space-separated expanded tokens.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['da', 'ele', 'genial', 'hasta', 'luego']\n",
            "Entities: []\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOT: Hasta luego!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    618\u001b[0m         \"\"\"\n\u001b[0;32m--> 619\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-66a6e7abf19b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mintents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mIDF\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIDF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}